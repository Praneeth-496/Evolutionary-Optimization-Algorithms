# -*- coding: utf-8 -*-
"""tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y3olh0yFlvrhFQtm48CtViWz3MIfYo_P
"""



from typing import List, Tuple
import numpy as np
from ioh import get_problem, logger, ProblemClass
from GA import s4454537_s4174089_GA, create_problem

# Set global budget for tuning
budget = 5000000

# Reproducibility
np.random.seed(42)

# Hyperparameters to tune
hyperparameter_space = {
    "population_size": [200, 100, 50],
    "mutation_rate": [0.01, 0.05, 0.1],
    "crossover_rate": [0.9, 0.7, 0.5]
}

# Hyperparameter tuning function
def tune_hyperparameters() -> List:
    best_score = float('-inf')  # Initialize with the lowest score
    best_params = None

    # Create problems and their respective loggers
    F18, logger_18 = create_problem(dimension=50, fid=18)
    F23, logger_23 = create_problem(dimension=49, fid=23)

    # Iterate over all hyperparameter combinations
    for pop_size in hyperparameter_space["population_size"]:
        for mutation_rate in hyperparameter_space["mutation_rate"]:
            for crossover_rate in hyperparameter_space["crossover_rate"]:
                print(f"\nTesting: Pop Size={pop_size}, Mutation Rate={mutation_rate}, Crossover Rate={crossover_rate}")

                # Update global hyperparameters
                global population_size, mutation_rate_global, crossover_rate_global
                population_size = pop_size
                mutation_rate_global = mutation_rate
                crossover_rate_global = crossover_rate

                scores = []

                # Test on F18
                for i in range(4):  # Perform 4 independent runs for F18
                    print(f"  Running F18 - Trial {i + 1}")
                    best_fitness = s4454537_s4174089_GA(F18)
                    scores.append(best_fitness)
                    print(f"  Best Fitness in Trial {i + 1}: {best_fitness}")
                    F18.reset()

                # Test on F23
                for i in range(4):  # Perform 4 independent runs for F23
                    print(f"  Running F23 - Trial {i + 1}")
                    best_fitness = s4454537_s4174089_GA(F23)
                    scores.append(best_fitness)
                    print(f"  Best Fitness in Trial {i + 1}: {best_fitness}")
                    F23.reset()

                # Calculate average score for the current hyperparameter combination
                avg_score = np.mean(scores)
                print(f"  Average Score for combination: {avg_score}")

                # Update the best parameters if the current combination performs better
                if avg_score > best_score:
                    best_score = avg_score
                    best_params = [pop_size, mutation_rate, crossover_rate]
                    print(f"  New Best Parameters Found: {best_params} with Score: {best_score}")

    # Close the loggers
    logger_18.close()
    logger_23.close()

    return best_params


if __name__ == "__main__":
    # Hyperparameter tuning to determine the best parameters for both problems
    print("Starting Hyperparameter Tuning...")
    best_params = tune_hyperparameters()

    print("\nBest Hyperparameters Found:")
    print(f"Population Size: {best_params[0]}")
    print(f"Mutation Rate: {best_params[1]}")
    print(f"Crossover Rate: {best_params[2]}")